# WO-6 — Scores (Π-safe) + FREE predicate

**Goal:** build a Π-safe score tensor (\hat s\in\mathbb R^{N\times C}) that depends only on bins/mask/verified-free transforms (never on raw color IDs), convert to integer costs, and implement a **FREE gate** that certifies a candidate symmetry (U) is *free* iff it preserves both the score field ((\hat s\circ U=\hat s)) and all emitted constraints (mask/equalizers/faces), i.e. (A,U=A). Tests: `ŝ∘U == ŝ` and constraint invariance.

## Anchors to read before coding

* ` @docs/anchors/02_addendum.md ` §B (Π-safe scores; FREE-invariance rule), §G (FREE predicate)
* ` @docs/anchors/03_annex.md ` A.1–A.3 (byte-exact equality, int64 costs; lex rules)
* ` @docs/anchors/04_engg_spec.md ` §7 “Scores (Π-safe) + FREE gate”

Everything below must match those anchors verbatim.

---

## Mature libraries & exact calls (no algorithm invention)

* **NumPy** (only) for all ops:

  * Byte-exact equality for invariance checks: `numpy.array_equal(a, b)` ([NumPy][1])
  * Spatial rolls for FREE torus shifts: `numpy.roll(a, shift, axis=0/1)` ([NumPy][2])
  * Channel permutations for FREE palette relabels: `numpy.take(a, indices, axis=-1)` (or `take_along_axis`) ([NumPy][3])
  * Standard broadcasting rules for building (\hat s) from bin/mask features (Π-safe): see NumPy broadcasting docs ([NumPy][4])
* **SciPy sparse** (only for constraint containers you may need to touch for invariance checks): CSR matrices are well-documented and deterministic for row access (do not solve anything in WO-6). ([SciPy Documentation][5])

No RNG. No threads/JIT. No other libraries.

---

## Module: `src/arcsolver/scores.py`

### 1) Build Π-safe score field

```python
from __future__ import annotations
import numpy as np
from .config import SCALE, SCORE_F64, INT_DTYPE, assert_score_bounds

def build_scores_pi_safe(
    H: int, W: int,
    A_mask: np.ndarray,           # (N,C) bool from WO-4
    bin_ids: np.ndarray,          # (N,) int64 from WO-1
    stage_features: dict[str, np.ndarray] | None = None,  # optional Π-safe extras
) -> np.ndarray:
    """
    Returns ŝ of shape (N,C) float64. Π-safe by construction:
    depends only on bins/mask/verified FREE transforms; never on raw color IDs.
    """
    N, C = A_mask.shape
    sh = np.zeros((N, C), dtype=SCORE_F64)

    # Example Π-safe template (weights are simple constants; adjust as needed, still Π-safe):
    # +w_mask for allowed entries; +w_bin per-bin priors; +optional stage priors (all Π-safe)
    w_mask = 1.0
    w_bin  = 0.1
    sh += w_mask * A_mask.astype(SCORE_F64)

    # Per-bin prior replicated to channels by broadcasting (Π-safe; no color IDs)
    # bin_counts per pixel are just 1; we map bin IDs to a small bias vector
    # Example: favor interior bins slightly
    # Make a small table of size num_bins -> bias, then broadcast
    # (You already hold num_bins in ctx.bins.)
    # stage_features may include verified FREE labels you averaged earlier.
    # DO NOT read color ids here.

    assert_score_bounds(sh)
    return sh
```

**Notes**

* Π-safe means: your (\hat s) can **only** use the bin partition, the A-mask, and (optionally) verified FREE transforms you’ve already projected/averaged; never the raw color labels.
* Broadcasting is the standard vectorized way to add per-pixel or per-bin terms across the channel axis; NumPy’s broadcasting semantics are documented and deterministic. ([NumPy][4])

### 2) Convert to integer costs (for flows later)

```python
def to_int_costs(sh: np.ndarray) -> np.ndarray:
    """
    cost = round(-ŝ * SCALE) as int64; never used in feasibility checks and never mixed with floats.
    """
    cost = np.rint(-sh * SCALE).astype(INT_DTYPE, copy=False)
    return cost
```

### 3) FREE predicate (decidable, per anchors §G)

```python
def check_free_predicate(
    sh: np.ndarray,                      # (N,C) float64 scores
    A_mask: np.ndarray,                  # (N,C) bool
    equalizer_rows: list[tuple[int,int,int]] | None,  # optional structure rows (WO-5)
    faces: dict | None,                  # optional row/col faces if present
    U: dict,                             # a candidate symmetry with keys {"type": "roll"|"perm", ...}
) -> tuple[bool, bool]:
    """
    Returns (cost_invariance_ok, constraint_invariance_ok).
    - cost invariance: array_equal(sh, apply_U_to_scores(sh, U))
    - constraint invariance: A U = A (and any emitted linear equalities preserved)
    """
    sh_U = apply_U_to_scores(sh, U)
    cost_ok = np.array_equal(sh, sh_U)  # byte-exact check per Annex A.1
    A_U = apply_U_to_mask(A_mask, U)
    constr_ok = np.array_equal(A_mask, A_U)

    # If you carry equalizer rows or faces as simple structures, confirm they permute to themselves under U.
    # e.g., for a roll, indices map deterministically; for a palette permutation, channel indices map via perm.
    # Keep the test byte-exact; no floats.

    return cost_ok, constr_ok
```

**Apply U implementations**

* **Spatial roll**: `np.roll(sh.reshape(H,W,C), shift=(dy,dx), axis=(0,1)).reshape(N,C)`; same for A_mask. ([NumPy][2])
* **Palette permutation** on channel axis: `np.take(sh, perm, axis=1)`; same for A_mask. ([NumPy][3])
  (If you precompute a canonical `perm` from WO-3, pass it in `U`.)

---

## Stage runner (no “god function”)

**File:** `src/arcsolver/stages_wo06.py`

```python
from __future__ import annotations
import numpy as np
from .pipeline import PipelineContext, STAGES
from .scores import build_scores_pi_safe, to_int_costs, check_free_predicate
from .receipts import write_stage_receipt

def run_wo06(ctx: PipelineContext) -> PipelineContext:
    # Preconditions: ctx.meet_mask (A_mask), ctx.bins, ctx.embedding are present (WO-4/WO-2)
    A = ctx.meet_mask["A_mask"]        # (N,C) bool
    H, W = ctx.embedding["H_out"], ctx.embedding["W_out"]
    bin_ids = ctx.bins["bin_ids"]      # (N,) int64
    sh = build_scores_pi_safe(H, W, A_mask=A, bin_ids=bin_ids, stage_features=None)
    costs = to_int_costs(sh)

    # FREE checks for the candidate verified symmetries (if any)
    free_maps = ctx.embedding.get("free_maps_verified", [])  # e.g., periods or palette relabels already verified
    checks = []
    all_cost_ok = True
    all_constr_ok = True
    for U in free_maps:
        cost_ok, constr_ok = check_free_predicate(sh, A, ctx.eq_struct.get("equalizers") if ctx.eq_struct else None,
                                                  ctx.eq_struct.get("faces") if ctx.eq_struct else None, U=U)
        checks.append({"U": U, "cost_invariance_ok": bool(cost_ok), "constraint_invariance_ok": bool(constr_ok)})
        all_cost_ok &= cost_ok; all_constr_ok &= constr_ok

    # store artifacts
    ctx.scores = {"scores_hash": _hash_nd(sh), "costs_hash": _hash_nd(costs), "free_checks": checks}

    # write receipt
    write_stage_receipt(ctx.task_id, "wo06", {
        "stage": "wo06",
        "scores": {"shape": list(sh.shape), "scores_hash": _hash_nd(sh)},
        "costs": {"shape": list(costs.shape), "costs_hash": _hash_nd(costs)},
        "free_checks": checks,
        "free_gate_all_ok": (all_cost_ok and all_constr_ok),
    }, out_dir=str(ctx.receipts_root))

    return ctx

STAGES[6] = run_wo06

# helper
def _hash_nd(a: np.ndarray) -> str:
    import hashlib
    return hashlib.sha256(a.tobytes(order="C")).hexdigest()
```

**Why this is correct**

* FREE invariance of scores is checked with **byte-exact** equality (`array_equal`). ([NumPy][1])
* Spatial rolls and palette permutations are applied with **documented NumPy functions** (`roll`, `take`), so the mapping is deterministic and vectorized. ([NumPy][2])
* Constraints invariance (`A U = A`) is likewise a byte-exact equality on the mask (and any row structures you choose to mirror).

---

## Receipts (first-class)

For each task `<tid>`, write `receipts/<tid>/wo06.json`:

```json
{
  "stage": "wo06",
  "scores":  { "shape": [N,10], "scores_hash": "<sha256>" },
  "costs":   { "shape": [N,10], "costs_hash": "<sha256>", "scale": 1000000 },
  "free_checks": [
    { "U": {"type":"roll","dy":py,"dx":px},
      "cost_invariance_ok": true,
      "constraint_invariance_ok": true
    },
    { "U": {"type":"perm","perm":[...10...]},
      "cost_invariance_ok": true,
      "constraint_invariance_ok": true
    }
  ],
  "free_gate_all_ok": true
}
```

* Hashes are SHA-256 of **raw bytes** (C-order); this is our deterministic fingerprint. ([SciPy Documentation][5])

---

## Harness / pipeline (no “god function”)

* You’ve already switched to `pipeline.py` registry. Add:

```python
# in src/arcsolver/stages_wo06.py
from .pipeline import STAGES
STAGES[6] = run_wo06
```

* Keep the orchestrator:

```bash
bash scripts/run_harness.sh --upto-wo 6 --strict
```

This will run WO-1→WO-6 in order via the registry, **reusing artifacts** from earlier stages and **only writing WO-6 receipts** now.

---

## Progress metrics to aggregate (generic harness already supports)

In `progress/progress_wo06.json`, accumulate:

* `free_cost_invariance_ok` = share of tasks where **all** verified (U) satisfy `ŝ∘U == ŝ`.
* `free_constraint_invariance_ok` = share of tasks where **all** verified (U) satisfy `A U == A`.
* (Optional) `scores_hash_stable` = cross-run determinism (same scores hash).

---

## Reviewer instructions (exact)

1. Run on all 1000 tasks:

   ```bash
   bash scripts/run_harness.sh --upto-wo 6 --strict
   ```
2. Confirm per-task receipts `wo06.json` are present and **byte-identical** across two runs.
3. Open `progress/progress_wo06.json` and report:

   * `free_cost_invariance_ok = 100%`
   * `free_constraint_invariance_ok = 100%`
4. Spot-check a few tasks:

   * For a roll (U=(p_y,p_x)), verify `scores_hash` equals `scores_hash` after `roll` (we log both in receipt). The definition of `np.roll` is standard. ([NumPy][2])
   * For a palette permutation, verify `np.take(sh, perm, axis=1)` reproduces `sh` byte-exact (that’s our check). ([NumPy][3])
5. Any red metric is an **implementation gap in WO-6** (not UNSAT). Fix and re-run.

---

## Anti-optimization guard (CPU)

* All operations are O(N·C) vectorized NumPy; ARC grids are tiny.
* No multithreading/JIT; byte-exact equality and deterministic order only.

---

## Why this is on-spec (and where the web docs back the primitives)

* Byte-exact equality for invariance: `numpy.array_equal` (we use equality, not tolerance) ([NumPy][1])
* Spatial FREE maps: `numpy.roll` across axes is documented and deterministic ([NumPy][2])
* Channel FREE maps: `numpy.take(..., axis=1)` (or `take_along_axis`) applies canonical permutations on the color axis ([NumPy][3])
* Π-safe scoring via broadcasting is pure NumPy; broadcasting rules are standard and deterministic ([NumPy][4])
* If you store constraint structures sparsely, CSR is the documented SciPy container for row-wise invariance checks (no solving) ([SciPy Documentation][5])

---

## Deliverables checklist (implementer)

* [ ] `build_scores_pi_safe(...)` produces Π-safe `ŝ (N×C)` (no color-ID use), with `assert_score_bounds` before converting costs.
* [ ] `to_int_costs(...)` implements `round(-ŝ*SCALE)` to int64 (no floats in feasibility).
* [ ] `check_free_predicate(...)` applies `U` via `np.roll` (spatial) and/or `np.take` (channels); returns two booleans (cost & constraint invariance).
* [ ] `stages_wo06.run_wo06(...)` writes `wo06.json` with hashes and per-map checks; registers `STAGES[6]`.
* [ ] Harness aggregates `free_cost_invariance_ok` & `free_constraint_invariance_ok`.

## Acceptance checklist (reviewer)

* [ ] Receipts `wo06.json` byte-stable across two runs.
* [ ] `free_cost_invariance_ok = 100%`, `free_constraint_invariance_ok = 100%` for all tasks.
* [ ] Spot-checks: `ŝ∘U == ŝ` using `roll`/`take`, and `A U == A` checked byte-exactly.
* [ ] Any failure is an **implementation gap** in WO-6; fix before WO-7.

---
# Patch and Clarifications
## Patch WO-6 (Scores (Π-safe) + FREE predicate) — **drop-in changes**

### A) Tighten Π-safe definition and enforce it at runtime

**Anchors:** 02_addendum §B (Π-safe scores, FREE invariance), 03_annex A.1–A.3 (byte-exact).

#### A1. Allowed score forms (hard rule)

For every pixel (p) and color (c),
[
\hat s_{p,c} = \alpha_0 ;+; \alpha_1 \cdot \mathbf 1{A_{p,c}=1};+; f_{\text{pixel}}(p) ;+; f_{\text{bin}}(\text{bin}(p))
]
where:

* (f_{\text{pixel}}(p)) depends **only** on geometry (row/col position) or on **per-pixel scalars** that are **permutation-invariant** over colors (e.g., bin-constant, or edge distance), applied **identically** to all channels at that pixel.
* (f_{\text{bin}}(\cdot)) is a per-bin scalar broadcast over channels.
* **No** term may depend on “which specific color is admitted” (no channel-conditioned weights beyond (\mathbf 1{A_{p,c}=1})).

**Implication:** The controversial `feasibility_count = A_mask.sum(axis=1)` is **allowed only if used as a per-pixel scalar broadcast identically to all channels** (Π-safe). It is **not** allowed to weight channels differently based on that count (which would encode color identity through A). To avoid future drift, we’ll remove it from the default template.

#### A2. Code changes: `src/arcsolver/scores.py`

Replace your builder with this **strict template** and a Π-safe self-check:

```python
def build_scores_pi_safe(H: int, W: int, A_mask: np.ndarray,
                         bin_ids: np.ndarray, *, use_feasibility_scalar=False) -> np.ndarray:
    """
    Returns ŝ with shape (N,C) float64.
    Π-safe: depends on (A[p,c]), per-pixel scalars identical across c, and per-bin scalars.
    """
    N, C = A_mask.shape
    sh = np.zeros((N, C), dtype=SCORE_F64)

    # Term 1: admits indicator per channel (Π-safe; channel-diagonal)
    w_mask = 1.0
    sh += w_mask * A_mask.astype(SCORE_F64)

    # Term 2: per-pixel scalar broadcast (Π-safe if identical across channels)
    # (Optional) feasibility scalar — apply identically across c OR omit by default.
    if use_feasibility_scalar:
        feas = A_mask.sum(axis=1)           # (N,)
        # Normalize to [0,1] deterministically
        feas_norm = (feas / max(1, feas.max())).astype(SCORE_F64)
        sh += feas_norm[:, None] * 0.05     # small, identical boost

    # Term 3: geometry-only scalar broadcast (Π-safe)
    rows = np.arange(H, dtype=np.float64)
    cols = np.arange(W, dtype=np.float64)
    rr, cc = np.meshgrid(rows, cols, indexing="ij")
    center_r = (H - 1) / 2.0
    center_c = (W - 1) / 2.0
    dist = np.sqrt((rr - center_r) ** 2 + (cc - center_c) ** 2)
    maxd = max(1.0, dist.max())
    centrality = 1.0 - dist / maxd
    sh += centrality.reshape(N, 1) * 0.1

    assert_score_bounds(sh)
    return sh
```

#### A3. Π-safe **equivariance** self-test (runtime, deterministic)

Add:

```python
def assert_pi_safety_equivariance(sh: np.ndarray, A: np.ndarray, bin_ids: np.ndarray,
                                  H: int, W: int) -> None:
    """
    Deterministic Π-safe check:
    Permute channels by a fixed non-trivial palette permutation π
    and rebuild ŝ from permuted A; require sh_π == take(sh, π, axis=1).
    """
    # Fixed π: swap (1,2); leave others unchanged
    perm = np.arange(sh.shape[1], dtype=np.int64)
    if sh.shape[1] >= 3:
        perm[1], perm[2] = perm[2], perm[1]

    # recompute ŝ from permuted A
    A_perm = np.take(A, perm, axis=1)                                 # channel permute (documented) :contentReference[oaicite:1]{index=1}
    sh_perm_rebuilt = build_scores_pi_safe(H, W, A_perm, bin_ids, use_feasibility_scalar=False)

    # compare to permuted original ŝ
    sh_perm_taken = np.take(sh, perm, axis=1)                          # channel permute  :contentReference[oaicite:2]{index=2}
    if not np.array_equal(sh_perm_rebuilt, sh_perm_taken):             # byte-exact check :contentReference[oaicite:3]{index=3}
        raise RuntimeError("Π-safe equivariance failed: ŝ does not commute with palette permutation.")
```

> This addresses **ISSUE #2** (missing Π-safe verification) with an explicit, deterministic equivariance test. It is **not** a “nice to have”—it enforces our anchor (“never center color IDs”) as a program invariant.

---

### B) FREE gate must include **all** constraints (mask + equalizers + faces)

**Anchors:** 02_addendum §G (FREE predicate: (A,U=A) for all emitted equalities), 03_annex A.1–A.3 (byte-exact).

#### B1. Persist structural constraints from WO-5 (or deterministically rebuild)

* **Equalizers:** in WO-5 stage, persist a canonical set of **edge rows** to cache (and keep in `ctx.eq_struct`):

  ```
  .cache/<task>/wo05.equalizers.npz
    -> arrays: bins[], colors[], edges[]    # edges[k] is (E_k,2) int64 array of (p_i,p_j) pairs
  ```

  Receipt still carries counts/hashes; the **rows** need not be in the receipt.
  Trees are unique with BFS from a fixed root (SciPy `csgraph.breadth_first_tree`), so cached edges are deterministic. ([SciPy Documentation][2])
* **Faces (if present):** persist `R[r,c]` and `S[j,c]` as int64 to `.cache/<task>/wo05.faces.npz` and store a pointer in `ctx.eq_struct["faces"]`.

If the cache file is missing at WO-6, **rebuild deterministically** using WO-5 rules and then check invariance—do not silently skip.

#### B2. Transport rules for constraints under a candidate FREE map (U)

* **Spatial roll** (U=(\Delta y,\Delta x)):

  * **Mask:** `A' = np.roll(A.reshape(H,W,C), (dy,dx), axis=(0,1)).reshape(N,C)`; require `array_equal(A, A')`. ([NumPy][3])
  * **Equalizers:** map each edge `(p_i,p_j,c)` to `((φ(p_i),φ(p_j),c))`, where `φ(r,c)=( (r+dy)%H, (c+dx)%W )`. Canonicalize pairs `(min,max)` in raster order and compare sorted edge lists byte-exact.
  * **Faces:** circularly shift rows by `dy` and cols by `dx` (`np.roll(R, dy, axis=0)`, `np.roll(S, dx, axis=0)`), require equality.

* **Palette permutation** (U=\sigma):

  * **Mask:** `A' = np.take(A, perm, axis=1)`; require equality. ([NumPy][4])
  * **Equalizers:** color index maps via `σ`: edges stay on same pixel pairs; require the permuted set equals the original set for each `σ` in the verified symmetry group.
  * **Faces:** permute color axis: `R' = np.take(R, perm, axis=1)`, `S' = np.take(S, perm, axis=1)`; require equality.

> All comparisons use `np.array_equal` (byte-exact). ([NumPy][1])

#### B3. Code changes: `check_free_predicate` (WO-6)

Expand to use equalizers/faces (if present). Sketch:

```python
def check_free_predicate(sh, A_mask, eq_rows, faces, U, H, W):
    # 1) cost invariance
    sh_U = apply_U_scores(sh, U, H, W)     # roll or take
    cost_ok = np.array_equal(sh, sh_U)

    # 2) mask invariance
    A_U  = apply_U_mask(A_mask, U, H, W)
    mask_ok = np.array_equal(A_mask, A_U)

    # 3) equalizers invariance (if present)
    eq_ok = True
    if eq_rows is not None:
        eq_rows_U = transport_equalizer_rows(eq_rows, U, H, W)
        eq_ok = equalizer_sets_equal(eq_rows, eq_rows_U)   # sorted pairs compare

    # 4) faces invariance (if present)
    faces_ok = True
    if faces is not None:
        R_U, S_U = transport_faces(faces["R"], faces["S"], U)
        faces_ok = np.array_equal(faces["R"], R_U) and np.array_equal(faces["S"], S_U)

    return cost_ok, (mask_ok and eq_ok and faces_ok)
```

Implement `apply_U_scores`, `apply_U_mask`, `transport_equalizer_rows`, and `transport_faces` with **documented** `np.roll`/`np.take` as above. ([NumPy][3])

This resolves **ISSUE #4** (structure mismatch) and **ISSUE #3/5/6** (FREE maps & invariance scope).

---

### C) Candidate FREE maps must come from **verified earlier WOs**

**Anchors:** 02_addendum §B/§C (periods & color symmetry are FREE only if verified exactly).

* **WO-2 (periods):** store once in `ctx.embedding["free_maps_verified"]`:
  `{"type": "roll", "dy": p_y, "dx": p_x, "verified_all_trainings": true}` **only if** the byte-equality `Y_i == roll(Y_i, p)` passed for **every** training output. (Use `np.roll`, `np.array_equal`.) ([NumPy][3])
* **WO-3 (color symmetry):** if you found a subgroup (H\subset S_{10}) such that **all** aligned training outputs are byte-identical under every (\pi\in H), export as:
  `{"type": "perm", "perm": [...], "verified_all_trainings": true}` for each non-identity (\pi).

**WO-6 must not synthesize new (U).** It **consumes** only maps flagged `verified_all_trainings: true`. This fixes **ISSUE #5–#6**.

---

## Receipts changes

**WO-6 receipt** already logs `free_checks`. Extend each entry with what was actually tested:

```json
{ "U": {"type":"roll","dy":py,"dx":px,"verified_all_trainings":true},
  "cost_invariance_ok": true,
  "mask_invariance_ok": true,
  "equalizers_invariance_ok": true,
  "faces_invariance_ok": true
}
```

Also write `"pi_safe_equivariance_ok": true` from the new self-test (A3).

---

## Harness / pipeline (no god function)

* Keep the stage registry in `src/arcsolver/pipeline.py`.
* `stages_wo02.py` and `stages_wo03.py`: add the `free_maps_verified` entries now (as above).
* `stages_wo05.py`: persist `equalizers_rows` (NPZ) and `faces` (if present).
* `stages_wo06.py`: consume `ctx.embedding["free_maps_verified"]`, `ctx.eq_struct["equalizers_rows"]`, and `ctx.eq_struct["faces"]` if present; otherwise **deterministically rebuild** equalizers from WO-5 rules (same A-mask & bins) before checking invariance.

All invariance checks use **byte-exact** `np.array_equal`, and transforms use **documented** `np.roll` and `np.take`. ([NumPy][1])

---

## Why this resolves each reported issue

* **ISSUE #1 (Π-safe violation):** We forbid any channel-conditioned use of `A` beyond the indicator term; per-pixel scalars are allowed only if broadcast identically. We also add an **equivariance self-check** to catch violations automatically (palette permutation on channels must commute).
* **ISSUE #2 (no Π-safe verification):** The new `assert_pi_safety_equivariance` enforces it at runtime.
* **ISSUE #3 (spatial centrality):** we keep it and clarify it is purely geometric (Π-safe).
* **ISSUE #4 (equalizer rows structure):** we persist canonical edge rows (or rebuild deterministically) and transport them under (U).
* **ISSUE #5–#6 (FREE map candidates):** WO-2/WO-3 now **export verified maps**; WO-6 uses only those.

---

## Reviewer instructions

Run over all 1000 tasks:

```bash
bash scripts/run_harness.sh --upto-wo 6 --strict
```

Expect in `progress_wo06.json`:

* `pi_safe_equivariance_ok = 100%`
* `free_cost_invariance_ok = 100%`
* `free_constraint_invariance_ok = 100%` (this includes mask + equalizers + faces)

Spot-check:

* `scores_hash` unchanged after channel permutation when **rebuilding** from permuted `A` (equivariance).
* For a verified roll ((p_y,p_x)) and any verified palette symmetry, all invariance booleans are **true**.

Any red metric = **implementation gap** in WO-6 (not UNSAT). Fix and re-run.

---

## Quick code utilities (you can paste)

```python
def apply_U_scores(sh, U, H, W):
    if U["type"] == "roll":
        dy, dx = int(U["dy"]), int(U["dx"])
        return np.roll(sh.reshape(H,W,-1), shift=(dy,dx), axis=(0,1)).reshape(-1, sh.shape[1])   # :contentReference[oaicite:11]{index=11}
    if U["type"] == "perm":
        return np.take(sh, U["perm"], axis=1)                                                   # :contentReference[oaicite:12]{index=12}
    raise ValueError("unknown U")

def apply_U_mask(A, U, H, W):
    return apply_U_scores(A.astype(np.int8), U, H, W).astype(bool)

def transport_equalizer_rows(eq_rows, U, H, W):
    # eq_rows: list of dicts: {"bin": s, "color": c, "edges": np.ndarray[(E,2)], dtype=int64}
    out = []
    if U["type"] == "roll":
        dy, dx = int(U["dy"]), int(U["dx"])
        def phi(p):
            r, c = divmod(int(p), W)
            r2 = (r + dy) % H; c2 = (c + dx) % W
            return r2 * W + c2
        for item in eq_rows:
            c = item["color"]; s = item["bin"]
            edges = item["edges"]
            mapped = np.sort(np.stack([np.vectorize(phi)(edges[:,0]),
                                       np.vectorize(phi)(edges[:,1])], axis=1), axis=1)
            out.append({"bin": s, "color": c, "edges": mapped})
        return out
    if U["type"] == "perm":
        perm = np.array(U["perm"], dtype=np.int64)
        for item in eq_rows:
            s = item["bin"]; edges = item["edges"]
            c = int(perm[item["color"]])
            out.append({"bin": s, "color": c, "edges": edges})
        return out
    raise ValueError("unknown U")
```

All byte-equality checks use `np.array_equal` (documented) and transforms use `np.roll`/`np.take` (documented). ([NumPy][1])

---
## Another Patch
Yes—do the proper WO-3 fix first, then re-run WO-6. The reviewer is right: Hungarian permutations are **alignments**, not symmetries. SciPy’s `linear_sum_assignment` solves a **minimum-cost assignment** (workers↔jobs) and says nothing about preserving the image under a palette permutation, so those permutations must not be treated as FREE maps. ([SciPy Documentation][1])

Below is a tight, anchored patch plan:

---

# PATCH PLAN

## Part A — Fix WO-3 to export **verified color symmetries** (small, surgical)

### A1. What “verified symmetry” means (anchors)

From your addendum 02 §C/§G: only export a palette permutation π if **every aligned training output** is byte-identical under that permutation. In code, for each candidate π:

```
all(np.array_equal(Y_i, np.take(Y_i, π, axis=1)) for i in trainings)
```

Use `np.array_equal` for byte-exact equality, and `np.take(..., axis=1)` for channel permutations (both documented). ([NumPy][2])

### A2. How to build the tiny candidate set (fast)

1. After WO-3 alignment, build per-color **layers** for each training:

   ```
   L_i[c] = (Y_i == c)    # boolean layer (H,W) or flattened (N,)
   ```
2. Two colors can belong to the same orbit only if their layers are **identical in every training**:

   ```
   equal_in_all_trainings(c,d) ⇔ ∀i: np.array_equal(L_i[c], L_i[d])
   ```

   Partition {0..9} into **orbits** by this relation. (Most orbits are size 1; sometimes you’ll get a small orbit like {3,7}.)
3. The symmetry subgroup is the **direct product** of symmetric groups on those orbits. For each orbit O of size m>1, any permutation σ∈S_m is a **candidate**. Export **only** those σ for which the whole output remains byte-identical (step A1).

This is tiny in practice (usually m≤2), so the verification loop is trivial.

### A3. Code patch (WO-3 runner)

* **Do not** export Hungarian permutations.
* **Do** export only the verified symmetries:

```python
# after alignment
verified = []
for orbit in orbits:                      # each orbit is a list of colors
    for pi in non_identity_perms(orbit):  # permutations inside orbit
        # build full 10-length perm array from orbit permutation
        perm = np.arange(10)
        for idx, c in enumerate(orbit): perm[c] = orbit[pi[idx]]
        ok = all(np.array_equal(Yi, np.take(Yi, perm, axis=1)) for Yi in aligned_train_outputs)  # byte-equal
        if ok:
            verified.append({"type": "perm", "perm": perm.tolist(), "verified_all_trainings": True})

ctx.embedding.setdefault("free_maps_verified", [])
ctx.embedding["free_maps_verified"].extend(verified)
# and also write them into wo03.json under "verified_color_symmetries"
```

* **Receipts (wo03.json)** add:

```json
"verified_color_symmetries": [
  {"perm":[...10...], "verified_all_trainings": true},
  ...
]
```

### A4. Why this is correct

* You’re proving **invariance** (FREE) by **byte-equal outputs** under a permutation (`np.array_equal`). ([NumPy][2])
* You apply permutations on the channel axis with **documented** `np.take`. ([NumPy][3])
* You do **not** use Hungarian for symmetry; SciPy’s doc makes clear it’s an **assignment** solver, not a symmetry test. ([SciPy Documentation][1])

---

## Part B — Adjust WO-6 to consume ONLY **verified** maps

### B1. Remove Hungarian from FREE candidate list

Delete the block that promotes Hungarian permutations into FREE candidates. Only accept:

* **Periods** from WO-2 *when verified across trainings* (byte-equal equality under `np.roll`), and
* **Color symmetries** from WO-3 *with* `verified_all_trainings: true`.

Transport for rolls uses `np.roll` (documented). ([NumPy][4])

### B2. If no verified maps exist

`free_cost_invariance_ok` and `free_constraint_invariance_ok` are **vacuously true** (and the receipt should include `"no_verified_free_maps": true`).

---

## Part C — Tie up the two ancillary gaps the reviewer flagged

1. **Equalizer rows for FREE check**
   Persist the canonical equalizer edge list in WO-5 (or deterministically rebuild in WO-6) and include them in the FREE predicate’s constraint-invariance test:

   * **Roll**: map each endpoint p→φ(p) where φ is the torus shift; canonicalize each pair `(min,max)` in raster order; compare sorted lists byte-exact.
   * **Perm**: keep endpoints, map color c→π(c); compare per-color edge sets.
     Use `np.array_equal` for byte equality and SciPy **BFS tree** (unique given a start) for deterministic edge lists. ([SciPy Documentation][5])

2. **Π-safe score builder self-check**
   Keep scores Π-safe by construction (bin/pixel scalars broadcast across channels + the admits indicator). Add a deterministic **equivariance** self-test: permute channels by a fixed non-trivial π, rebuild ŝ from `A_perm`, and require `build(A_perm) == take(ŝ, π, axis=1)` (byte-exact). Use `np.take` and `np.array_equal`. ([NumPy][3])

---

# What will happen after these patches

* With Hungarian permutations removed as FREE candidates, WO-6’s metrics should jump to **100%** (vacuously true) wherever there are no verified maps.
* For the few tasks with true **periodic symmetries**, your WO-2 period entries (verified with byte-equality via `np.roll`) will be exercised and should pass. ([NumPy][4])
* When WO-3 now exports **verified** color symmetries, WO-6 will check real palette symmetries and remain green (or surface genuine defects in FREE transport code).

---

# Quick diffs you can hand to the implementer

**1) WO-6 (runner/harness):** remove the Hungarian block

```diff
- if "hungarian" in wo3_receipt:
-     for h in wo3_receipt["hungarian"]:
-         if "perm" in h:
-             free_map_candidates.append({"type":"perm","perm": h["perm"], "source":"wo3_hungarian"})
+ # Only consume verified maps:
+ free_map_candidates.extend(wo3_receipt.get("verified_color_symmetries", []))
```

**2) WO-3 (runner):** add verified symmetry export (see A3 patch)

**3) WO-5 (runner):** write canonical equalizer rows to `.cache/<task>/wo05.equalizers.npz` (BFS tree from fixed root; raster-sorted pairs). SciPy `breadth_first_tree` returns the unique BFS tree for a start node. ([SciPy Documentation][5])

**4) WO-6 (scores):** add Π-safe equivariance self-test (see Part C-2)

---

# Why this is anchored & not guesswork

* **Assignment ≠ symmetry**: SciPy’s `linear_sum_assignment` documentation defines the problem as finding a minimum-cost matching; it does not claim invariance properties. Using those permutations as FREE maps is incorrect. ([SciPy Documentation][1])
* **FREE transport & equality are well-defined** with **documented NumPy** primitives: `np.roll` for spatial torus shifts; `np.take` for channel permutations; `np.array_equal` for byte-exact comparisons. ([NumPy][4])
* **BFS tree determinism** (SciPy’s csgraph): breadth-first tree from a specified node is **unique**—a clean basis for canonical equalizer edge sets. ([SciPy Documentation][5])
* **Laplacian/rows** you already follow for harmonic fill; unchanged by this patch. ([SciPy Documentation][6])

---

