# WO-0 — Core types & guards (determinism, dtypes, lex orders, env)

## Scope (what lands in this WO)

Set the deterministic runtime contract for the whole repo and define canonical types, constants, and helpers. Nothing algorithmic. This is the foundation every later WO leans on.

## Read these anchors before coding

* ` @docs/anchors/03_annex.md ` (A.1–A.3, implementation tolerances; meta-theorems context)
* ` @docs/anchors/05_contracts.md ` (entire file; these are the non-negotiable rules)
* ` @docs/anchors/04_engg_spec.md ` (sections “0) Global types & helpers” and the deterministic orders list)

Everything you implement below must match those anchors verbatim.

---

## Library choices (mature, well-documented; no algorithm invention)

You will **only** use these here (import and assert versions; no optional packages):

* **Python stdlib:** `os`, `sys`, `platform`, `pathlib`, `json`, `hashlib`, `typing`, `dataclasses`, `enum`, `subprocess`, `textwrap`
* **NumPy:** `numpy` (arrays & dtype checks)
* **SciPy:** `scipy` (we assert presence for later Hungarian; do not call any algorithms yet)
* **OR-Tools:** `ortools.graph.pywrapgraph` (we assert presence for later min-cost flow; do not call yet)
* **(Optional presence check)** `skimage` or `scipy.ndimage` (connected-components later). Just probe availability.

No other libs. No RNG. No threading pools.

---

## Files to create/modify

### 1) `src/arcsolver/config.py`  (determinism guards + constants)

**Purpose:** Enforce single-thread, hash determinism, pinned dtypes, and shared constants at import time.

**Implement:**

```python
# src/arcsolver/config.py
from __future__ import annotations
import os, sys, platform
import numpy as np

# ---- Determinism env (must be set before heavy libs import) ----
def _set_env():
    os.environ.setdefault("OMP_NUM_THREADS", "1")
    os.environ.setdefault("OPENBLAS_NUM_THREADS", "1")
    os.environ.setdefault("MKL_NUM_THREADS", "1")
    os.environ.setdefault("NUMEXPR_NUM_THREADS", "1")
    os.environ.setdefault("PYTHONHASHSEED", "0")

_set_env()

# ---- Versions (assert pinned major/minor) ----
REQUIRED = {
    "python_major": (3, 11),
    "numpy": (2, 1),     # accept 2.1.x
    "scipy": (1, 13),    # accept 1.13.x
    "ortools": (9, 10),  # accept 9.10.x
}

def _assert_versions():
    import numpy, scipy
    try:
        from ortools.graph import pywrapgraph  # noqa: F401
    except Exception as e:
        raise RuntimeError("OR-Tools not properly installed") from e

    py_ver = sys.version_info
    if py_ver[:2] != REQUIRED["python_major"]:
        raise RuntimeError(f"Python must be 3.11.x, got {py_ver.major}.{py_ver.minor}")

    def _major_minor(mod, want):
        parts = tuple(map(int, mod.__version__.split(".")[:2]))
        if parts != want:
            raise RuntimeError(f"{mod.__name__} must be {want[0]}.{want[1]}.x, got {mod.__version__}")

    _major_minor(numpy, REQUIRED["numpy"])
    _major_minor(scipy, REQUIRED["scipy"])
_assert_versions()

# ---- Global constants (anchors 03 & 04) ----
PALETTE_C = 10
BACKGROUND = np.int32(0)
PAD_SENTINEL = np.int32(-1)
INT_DTYPE = np.int64
GRID_DTYPE = np.int32
SCORE_F64 = np.float64
SCALE = 1_000_000  # cost = round(-ŝ * SCALE)

# Lex orders (anchors 03.A.3, 04 §0)
PALETTE_ORDER = tuple(range(PALETTE_C))  # 0..9
PIXEL_LEX = "row_col_asc"
PERIOD_LEX = "py_first_px_second_asc"
CANVAS_LEX = "H_W_asc"
SIG_LEX_FIELDS = ("neg_count", "row_hist", "col_hist", "bin_hist", "color_id")

# Hard bounds to keep int64 safe
MAX_ABS_SCORE = 1_000_000  # so |cost| <= 1e12 for 1k px

def assert_score_bounds(shat: np.ndarray):
    if not np.all(np.abs(shat) <= MAX_ABS_SCORE):
        raise RuntimeError("ŝ out of bounds; violates int64 cost budget")

def enforce_dtypes(arr: np.ndarray, kind: str) -> np.ndarray:
    if kind == "grid":
        return np.asarray(arr, dtype=GRID_DTYPE)
    if kind == "idx" or kind == "count" or kind == "cost":
        return np.asarray(arr, dtype=INT_DTYPE)
    if kind == "score":
        return np.asarray(arr, dtype=SCORE_F64)
    raise ValueError(f"unknown dtype kind {kind}")
```

### 2) `src/arcsolver/types.py`  (dataclasses + enums)

**Purpose:** Canonical type shapes used everywhere.

**Implement (outline):**

```python
from __future__ import annotations
from dataclasses import dataclass
from typing import Tuple, List, Dict
import numpy as np
from .config import GRID_DTYPE, INT_DTYPE

@dataclass(frozen=True)
class Canvas:
    H: int
    W: int

@dataclass(frozen=True)
class Grid:
    data: np.ndarray  # (H,W) int32

    @property
    def shape(self) -> Tuple[int,int]:
        return self.data.shape

    def assert_dtype(self):
        if self.data.dtype != GRID_DTYPE:
            raise RuntimeError(f"grid dtype must be {GRID_DTYPE}, got {self.data.dtype}")

@dataclass(frozen=True)
class Component:
    color: int
    pixels: List[Tuple[int,int]]

@dataclass(frozen=True)
class Signatures:
    # per-color signatures prepared for alignment; store as dict[color] -> tuple
    by_color: Dict[int, Tuple]
```

### 3) `src/arcsolver/utils/hash_utils.py`  (byte-stable hashing)

**Purpose:** Receipts need stable hashes across platforms.

**Implement:**

```python
import hashlib, json, numpy as np
from typing import Any

def sha256_bytes(b: bytes) -> str:
    return hashlib.sha256(b).hexdigest()

def hash_ndarray_int(a: np.ndarray) -> str:
    if not np.issubdtype(a.dtype, np.integer):
        raise RuntimeError("hash_ndarray_int requires integer dtype")
    return sha256_bytes(a.tobytes(order="C"))

def hash_json_canonical(obj: Any) -> str:
    s = json.dumps(obj, sort_keys=True, separators=(",", ":"), ensure_ascii=False)
    return sha256_bytes(s.encode("utf-8"))
```

### 4) `src/arcsolver/receipts.py`  (stage-receipt writer)

**Purpose:** Always-on receipts; even at WO-0 we emit env & contract hashes per task.

**Implement (minimal at WO-0):**

```python
from __future__ import annotations
import json, os
from pathlib import Path
from typing import Dict, Any
from .config import REQUIRED, GRID_DTYPE, INT_DTYPE, SCALE, MAX_ABS_SCORE

def write_stage_receipt(task_id: str, stage: str, payload: Dict[str, Any], out_dir="receipts"):
    td = Path(out_dir) / task_id
    td.mkdir(parents=True, exist_ok=True)
    fp = td / f"{stage}.json"
    with fp.open("w", encoding="utf-8", newline="\n") as f:
        json.dump(payload, f, sort_keys=True, ensure_ascii=False, separators=(",", ":"))
        f.write("\n")

def make_env_payload() -> Dict[str, Any]:
    import numpy, scipy
    from ortools.graph import pywrapgraph  # noqa: F401
    return {
        "stage": "wo00",
        "runtime": {
            "python": f"{REQUIRED['python_major'][0]}.{REQUIRED['python_major'][1]}",
            "numpy": numpy.__version__,
            "scipy": scipy.__version__,
            "ortools": "ok",
        },
        "dtypes": {
            "GRID_DTYPE": str(GRID_DTYPE),
            "INT_DTYPE": str(INT_DTYPE),
            "SCALE": SCALE,
            "MAX_ABS_SCORE": MAX_ABS_SCORE,
        },
        "env": {
            "OMP_NUM_THREADS": os.getenv("OMP_NUM_THREADS"),
            "OPENBLAS_NUM_THREADS": os.getenv("OPENBLAS_NUM_THREADS"),
            "MKL_NUM_THREADS": os.getenv("MKL_NUM_THREADS"),
            "NUMEXPR_NUM_THREADS": os.getenv("NUMEXPR_NUM_THREADS"),
            "PYTHONHASHSEED": os.getenv("PYTHONHASHSEED"),
        },
    }
```

### 5) `src/arcsolver/harness.py`  (WO-aware runner; stage 0 checks)

**Purpose:** Run across all tasks, even at WO-0, and emit receipts.

**Implement (CLI skeleton):**

```python
from __future__ import annotations
import argparse, json
from pathlib import Path
from typing import Iterable
from .config import _set_env, _assert_versions  # re-export can be added
from .receipts import write_stage_receipt, make_env_payload

def list_task_ids(data_root: Path) -> Iterable[str]:
    # ARC json files are named <task_id>.json
    return sorted([p.stem for p in data_root.glob("*.json")])

def run_stage_wo0(data_root: Path):
    # At WO-0 we only assert env/versions and write receipts per task
    tasks = list_task_ids(data_root)
    payload = make_env_payload()
    for tid in tasks:
        write_stage_receipt(tid, "wo00", payload)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--data-root", type=Path, default=Path("data/arc"))
    ap.add_argument("--upto-wo", type=int, default=0)
    ap.add_argument("--strict", action="store_true")
    args = ap.parse_args()

    if args.upto_wo == 0:
        run_stage_wo0(args.data_root)
    else:
        raise SystemExit("WO>0 not implemented yet in this stage")

if __name__ == "__main__":
    main()
```

### 6) `scripts/run_harness.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail
export OMP_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export MKL_NUM_THREADS=1
export NUMEXPR_NUM_THREADS=1
export PYTHONHASHSEED=0

python -m src.arcsolver.harness --data-root data/arc --upto-wo 0 --strict
```

---

## Receipts (what we capture at WO-0, and why)

* **Per-task receipt `receipts/<task>/wo00.json`** with:

  * pinned versions, env threading vars, dtype constants, scaling constants.
* This proves our runtime satisfies **Annex A.1–A.3** and **Contracts / Global**.
* Reviewer can diff receipts across machines to confirm byte-identical environment.

---

## Runner/harness use (reviewer instructions)

**Pre-req:** Put ARC JSONs under `data/arc/` (flat, sorted naming).

**Run:**

```bash
bash scripts/run_harness.sh
```

**What to expect:**

* `receipts/<task_id>/wo00.json` for every task id discovered.
* No solver output yet, only environment receipts.

**Pass/fail criteria (WO-0):**

* All receipts exist.
* Receipt fields match the anchors:

  * Python = 3.11.x; numpy 2.1.x; scipy 1.13.x; ortools present.
  * All threads env vars = "1"; `PYTHONHASHSEED=0`.
  * Dtypes and constants exactly as in anchors.
* If any mismatch, this is an **implementation gap** (not an UNSAT task). Fix the environment or constants until receipts match.

---

## Unit checks worth adding now (tiny, no CI needed)

* A small test (or harness assert) that importing `arcsolver.config` does not alter after-import env (idempotent).
* A guard that raises if any module imports `random` / `numpy.random` (simple grep or runtime check).

---

## Anti-optimization note (CPU target)

* Do **not** introduce multithreading to “speed things up.” All later flows run in milliseconds on CPU per task.
* Do **not** add JIT/numba/numexpr. Determinism beats micro-wins.

---

## Adapters & hard improvements incorporated here

* **Determinism guards:** env single-thread (OMP/BLAS/MKL/NUMEXPR), `PYTHONHASHSEED=0`.
* **Version pins & asserts** as in Contracts.
* **No algorithm invention:** only stdlib + NumPy; we merely assert SciPy/OR-Tools are importable for later WOs.
* **Receipts first-class:** per-task env receipts from day one; harness CLI present.

---

## Deliverables checklist (for implementer)

* [ ] `src/arcsolver/config.py` with env guards, version asserts, constants, dtype helpers, score bound assert.
* [ ] `src/arcsolver/types.py` with `Canvas`, `Grid`, `Component`, `Signatures`.
* [ ] `src/arcsolver/utils/hash_utils.py` with stable hashing helpers.
* [ ] `src/arcsolver/receipts.py` with `write_stage_receipt()` and `make_env_payload()`.
* [ ] `src/arcsolver/harness.py` with `--upto-wo 0` implemented (per-task env receipts).
* [ ] `scripts/run_harness.sh` created.
* [ ] `requirements.txt` pinned (numpy 2.1.x, scipy 1.13.x, ortools 9.10.x; optionally scikit-image 0.23.x).
* [ ] `data/arc/` present with ARC JSONs (not in repo).

---

## Acceptance checklist (for reviewer)

**Anchor grounding**

* [ ] Matches `03_annex.md` A.1–A.3 and `05_contracts.md / Global` exactly.

**Determinism**

* [ ] Threads=1, hashseed=0 in receipts.
* [ ] Dtypes/constants match anchors.

**Runner**

* [ ] `scripts/run_harness.sh` produces receipts for **all 1000** tasks with no failures.
* [ ] Receipts are byte-stable if run twice (same SHA over the JSON file).

**Gap triage**

* If anything fails, it’s an **implementation gap in WO-0** (environment/guards), not an ARC “UNSAT.” Fix and re-run until green.

---
