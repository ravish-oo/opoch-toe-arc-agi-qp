# WO-3 — Color signatures + Hungarian adapter

Build Π-safe per-color signatures, align palettes deterministically with the Hungarian algorithm, and record receipts. This WO uses only mature, well-documented library calls (no custom algorithms).

## Anchors to read before coding

* `03_annex.md` A.1–A.3 (byte-exact equality; int64 only; lex rules)
* `04_engg_spec.md` §3 (Color alignment) and §0 (Global types & helpers)
* `05_contracts.md` (Canonical predicates; Orders; FREE vs PAID; Idempotence)

Everything below must match those anchors verbatim.

---

## Mature libraries & exact functions to use (no invention)

* **NumPy**:

  * `np.bincount(x, minlength=…)` (per-row/col/bin counts; non-negative int labels). ([NumPy][1])
  * Stable sorting when needed: `np.argsort(a, kind='stable')` or `np.sort(a, kind='stable')` (stable from NumPy 2.0). ([NumPy][2])
  * Byte-exact equality (for internal checks): `np.array_equal(a, b)` (no tolerances). ([NumPy][3])
* **SciPy**:

  * **Hungarian** assignment: `scipy.optimize.linear_sum_assignment(cost_matrix)` (a.k.a. Munkres). We encode our own lex tie-break *inside the costs* to make the result deterministic. ([SciPy Documentation][4])
* **Python stdlib**:

  * `hashlib.sha256` to hash raw `ndarray.tobytes(order='C')` into receipts (byte-level fingerprint). ([Python documentation][5])

No other libraries. No RNG. No threads/JIT.

---

## Module: `src/arcsolver/color_align.py`

### 1) Signature builder (Π-safe)

**Function**
`build_color_signatures(Y_emb: np.ndarray, bin_ids: np.ndarray, num_bins: int) -> dict[int, tuple]`

**Inputs**

* `Y_emb`: int32 (H_out, W_out), values in {−1, 0..9}; treat −1 as padding (ignore); 0..9 are colors.
* `bin_ids`: int64 flattened (H_out*W_out,) from WO-1 `build_bins`, raster order.
* `num_bins`: int.

**Computation (int64 everywhere):**
For each color `c ∈ {0..9}`:

* Mask: `M = (Y_emb == c)` (ignore −1).
* `count = int(M.sum(dtype=np.int64))`.
* Row histogram: `row_hist = np.bincount(np.nonzero(M)[0], minlength=H_out).astype(np.int64)`
* Col histogram: `col_hist = np.bincount(np.nonzero(M)[1], minlength=W_out).astype(np.int64)`
* Bin histogram: flatten `M` to `Mf = M.ravel(order='C')` and select `bin_ids[Mf]`, then
  `bin_hist = np.bincount(bin_ids[Mf], minlength=num_bins).astype(np.int64)`  ([NumPy][1])

**Signature tuple (must match anchors):**
`Σ(c) = ( -count, row_hist.tolist(), col_hist.tolist(), bin_hist.tolist(), c )`
Store in a dict `{c: Σ(c)}`. The leading `-count` makes “more pixels” lex-smaller, as specified.

> Note: use Python’s `tuple` of Python ints/lists for stable JSON; store counts as int64 while computing.

### 2) Canonical palette & cost matrix

**Function**
`canonical_palette_and_cost(Y_emb_list, bin_ids, num_bins) -> (canon_order, costs_per_training, sigs_per_training)`

* For each training output `Y_i_emb`, compute `sigs_i = build_color_signatures(...)`.
* **Canonical order**: concatenate all `Σ_i(c)` across trainings, **lex-sort** them with Python’s stable `sorted(key=tuple)` (or NumPy `argsort(kind='stable')` on a structured array) to get a canonical list of 10 color “slots”. This implements “Build a canonical palette by lexicographically sorting the multiset of signatures” from the spec.
* For each training, build a **10×10 int64 cost matrix** `C` where:

  * Base cost is L1 between flattened signature vectors (concatenate in the fixed order: `[-count, row_hist..., col_hist..., bin_hist...]`).
  * **Deterministic tie-break**: encode lex preference by adding a tiny **integer** column offset:
    `C[i, j] = base_cost(i, j) * LEX_SCALE + j`, with `LEX_SCALE = 1024` (safe margin so `j` never changes order when base costs differ; keep sums in int64).
    This guarantees a deterministic result even when base costs tie; SciPy doesn’t promise a tie-break contract, so it’s on us to encode it. ([SciPy Documentation][4])

### 3) Hungarian adapter (deterministic)

**Function**
`align_one_training(cost_matrix: np.ndarray) -> np.ndarray`

* Call `row_ind, col_ind = scipy.optimize.linear_sum_assignment(cost_matrix)`; build a permutation array `perm` of length 10 where `perm[orig_color] = assigned_canonical_slot`.  ([SciPy Documentation][4])
* Assertions:

  * `row_ind` and `col_ind` are length 10 and define a bijection.
  * Sum of chosen costs equals `cost_matrix[row_ind, col_ind].sum()`.
* Determinism: because we encoded `+ j` in costs and we build `C` in **fixed row/column order**, the mapping is unique and stable across runs.

### 4) Public API for WO-3

**Function**
`align_colors(train_outputs_emb: list[np.ndarray], bin_ids: np.ndarray, num_bins: int) -> (aligned_outputs, perms, sigs, canon_order, cost_hashes)`

* Compute signatures per training; compute canonical order and a cost matrix per training.
* Solve Hungarian per training to get `perm_i`; relabel channels in `Y_i_emb` accordingly to produce `aligned_outputs[i]`.
* Produce a **SHA-256 hash** of each cost matrix bytes for the receipt. ([Python documentation][5])
* Return aligned outputs, permutations list, signatures list, canonical order, and cost hashes.

---

## Receipts (first-class; what to write at WO-3)

For each task `<tid>`, write `receipts/<tid>/wo03.json`:

```json
{
  "stage": "wo03",
  "canonical_palette": { "order": [0,1,2,3,4,5,6,7,8,9] },   // indices of canonical slots
  "signatures": [
    { "training": 0, "by_color": { "0": Σ0, "1": Σ1, "...": "..." } },
    { "training": 1, "by_color": { "...": "..." } }
  ],
  "hungarian": [
    { "training": 0, "perm": [ ...10 ints... ], "total_cost": 123456, "cost_hash": "<sha256>" },
    { "training": 1, "perm": [ ... ], "total_cost": 123450, "cost_hash": "<sha256>" }
  ],
  "determinism": {
    "tie_encoded": true,                 // we used +j with LEX_SCALE
    "permutation_is_bijection": true
  }
}
```

* `Σk` are the signature tuples exactly as defined above (JSON-serializable).
* `cost_hash` is SHA-256 over `cost_matrix.tobytes(order='C')`. ([Python documentation][5])

---

## Harness changes (generic plumbing stays; add WO-3 metrics)

**`src/arcsolver/harness.py`**

* Implement `--upto-wo 3`: for each task,

  1. Load dict-based ARC JSON (glob `*.json` → open → iterate `train` keys).
  2. Ensure grids are already embedded from WO-2 (or use current training output shape if running WO-3 alone).
  3. Call `align_colors(...)`; write `wo03.json` receipt.
  4. Record metrics with the generic accumulator:

```python
acc_bool(progress, "hungarian_bijection_ok", is_bijection)
acc_bool(progress, "signature_tie_break_ok", tie_encoded and stable_perm_across_run)
```

* **Adversarial-tie self-check** (optional but recommended): if two or more columns in `C` are equal for some row (base-ties), verify that a second call in the same process returns the **same** `perm` (our encoded `+j` must force stability). If not, mark `signature_tie_break_ok = False`.

**`scripts/run_harness.sh`**

* Support `--upto-wo 3` and pass `--progress`.

---

## Reviewer instructions (what to run and report)

1. Run on all 1000 tasks:

   ```bash
   bash scripts/run_harness.sh --upto-wo 3 --strict
   ```
2. Confirm per-task receipts `wo03.json` exist and are **byte-identical** across two runs.
3. Open `progress/progress_wo03.json` and report:

   * `hungarian_bijection_ok = 100%`
   * `signature_tie_break_ok = 100%`
4. Spot-check a few tasks:

   * `cost_hash` unchanged across runs.
   * Each `perm` is a bijection of `{0..9}`; `total_cost` equals the sum of chosen entries.

**Any red metric = an implementation gap in WO-3** (never “dataset UNSAT”). Fix and re-run.

---

## Anti-optimization guard (CPU)

* All steps are O(HW) or O(10×10) per training; **CPU is more than enough**.
* No multithreading/JIT; no float tolerances; all costs are **int64**.

---

## Adapters & “hard improvements” enforced here

* Deterministic **lex tie-break inside the cost matrix** (`+ j` with `LEX_SCALE`), since SciPy doesn’t define a tie policy; this ensures stable, reproducible assignments. ([SciPy Documentation][4])
* Stable ordering everywhere (`sorted` or `argsort(kind='stable')`). ([NumPy][2])
* Integer histograms with `np.bincount` (fast, documented). ([NumPy][1])
* Byte-level cost hashes via `hashlib.sha256` for receipts. ([Python documentation][5])

---

## Deliverables checklist (implementer)

* [ ] `build_color_signatures(...)` returns Π-safe tuples `(−count, row_hist, col_hist, bin_hist, color_id)` (int64 counts).
* [ ] `canonical_palette_and_cost(...)` produces stable canonical order and **int64** 10×10 cost matrices with lex offset `C = base*LEX_SCALE + j`.
* [ ] `align_one_training(...)` wraps `scipy.optimize.linear_sum_assignment` and returns a **bijection** `perm` (len 10). ([SciPy Documentation][4])
* [ ] `align_colors(...)` returns aligned outputs, permutations, signatures, canonical order, and cost hashes; writes `wo03.json`.
* [ ] Harness `--upto-wo 3` calls `acc_bool` for `hungarian_bijection_ok` and `signature_tie_break_ok`.

## Acceptance checklist (reviewer)

* [ ] `hungarian_bijection_ok = 100%`.
* [ ] `signature_tie_break_ok = 100%` (perms repeat exactly across runs; cost hashes stable).
* [ ] Spot-checks: `perm` is a bijection; `total_cost` equals selected entries; receipts re-run byte-identical.

---
